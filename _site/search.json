[
  {
    "objectID": "teach/course-schedule.html",
    "href": "teach/course-schedule.html",
    "title": "On-campus Course Schedule - Fall 2025",
    "section": "",
    "text": "Data Updated: July 15, 2025 at 01:04 PM EST\n        Courses Offered: 14\n        Students Enrolled: 86/329\n    \n    \n\n\n\n\n\n    \n    \n        \n\n\n\nCourse\nSection\nCourse Name\nCredits\nEnrolled\nCapacity\nTimes\nLocation\nInstructor\nDates\n\n\n\n\nBUSA 603\nF1FF\nBUSA-603 Marketing Mgmt & Analytics\n4\n10\n22\nWed 1:00 PM - 3:00 PM\nFrasch Hall 417\nTBD\n9/29/2025 - 11/8/2025\n\n\nBUSA 695\nH1FF\nBUSA-695 Capstone in Business Analytics\n4\n4\n22\nMon 1:00 PM - 3:00 PM; Wed 1:00 PM - 3:00 PM\nFrasch Hall 422; Blended (Online + Wed in-person)\nTBD\n11/10/2025 - 12/20/2025\n\n\nCOMP 511 First Term\nU1FF\nCOMP-511 Foundation Data Struc & Obj Or\n4\n4\n22\nThu 3:00 PM - 5:00 PM\nFrasch Hall 417\nTBD\n8/18/2025 - 11/8/2025\n\n\nCOMP 611 First Term\nU1FF\nCOMP-611 Adv Data Structure and Program\n4\n10\n45\nThu 6:00 PM - 9:40 PM\nFrasch Hall 412\nTBD\n8/18/2025 - 11/8/2025\n\n\nCOMP 620\nR1FF\nCOMP-620 Analysis of Algorithms\n4\n5\n22\nWed 3:00 PM - 5:00 PM\nFrasch Hall 412\nTBD\n9/8/2025 - 11/29/2025\n\n\nCOMP 630 First Term\nU1FF\nCOMP-630 Issues/Database Management\n4\n0\n22\nTue 6:00 PM - 7:30 PM; Thu 10:00 AM - 12:00 PM\nFrasch Hall 422; Blended (Online + In-person)\nTBD\n8/18/2025 - 11/8/2025\n\n\nCOMP 691\nQ1FF\nCOMP-691 Capstone\n4\n11\n22\nWed 10:00 AM - 12:00 PM\nFrasch Hall 420\nTBD\n9/29/2025 - 12/20/2025\n\n\nDATA 610\nU1FF\nDATA-610 Big Data Analytics/Data Mining\n4\n6\n22\nMon 1:00 PM - 3:00 PM; Wed 10:00 AM - 12:00 PM\nFrasch Hall 422; Blended (Online + In-person)\nJiang Li\n8/18/2025 - 11/8/2025\n\n\nDATA 630 First Term\nU1FF\nDATA-630 Applied Database Management\n4\n3\n22\nMon 10:00 AM - 12:00 PM; Thu 1:00 PM - 3:00 PM\nFrasch Hall 422; Blended (Online + In-person)\nRickie Kidwell, Gayle DeGennaro\n8/18/2025 - 11/8/2025\n\n\nITEC 640\nQ1FF\nITEC-640 Project Management\n4\n2\n22\nTue 6:00 PM - 7:50 PM; Thu 6:00 PM - 7:50 PM\nFrasch Hall 422; Blended (Online + In-person)\nKhaled Jaber\n9/30/2025 - 12/18/2025\n\n\nITEC 660\nQ1FF\nITEC-660 Web Development and Deployment\n4\n1\n22\nTue 10:00 AM - 12:00 PM; Thu 10:00 AM - 12:00 PM\nFrasch Hall 412; Blended (Online + In-person)\nKemal Aydin\n9/30/2025 - 12/18/2025\n\n\nITEC 690\nQ1FF\nITEC-690 IT Strategy and Policy\n4\n14\n22\nMon 6:00 PM - 7:50 PM; Wed 1:00 PM - 3:00 PM\nFrasch Hall 424; Blended (Online + In-person)\nKhaled Jaber\n9/29/2025 - 12/17/2025\n\n\nMATH 601 First Term\nQ1FF\nMATH-601 Introduction to Analytics\n4\n16\n22\nThu 3:00 PM - 5:00 PM\nFrasch Hall 412\nJohn Fulton\n9/29/2025 - 12/20/2025\n\n\nPF 521 First Term\nE1FF\nPF-521 Advanced Learning Strategies\n0\n0\n20\nTue 10:00 AM - 12:00 PM; Thu 10:00 AM - 12:00 PM\nFrasch Hall 414\nMichael Klingler\n8/19/2025 - 9/25/2025\n\n\n\n\n    \n\n\n\n    \n        üì• Export Data\n        \n            üìä Export Table as CSV\n        \n        \n            Downloads the formatted course schedule as shown above, including first term indicators\n        \n    \n    \n\n\n\nData automatically generated from Franklin Course Catalog"
  },
  {
    "objectID": "teach.html",
    "href": "teach.html",
    "title": "Teaching Materials & Tools",
    "section": "",
    "text": "AI-Augmented Analytics Workflow ü§ñ\nüìã Practical AI Workflow Guide - Step-by-step methodology for integrating AI tools into analytical practice\n\n\n\nAnalytics Teaching Hub\nFranklin Analytics Teaching Hub is a collection of documents to assist instructors in teaching, including teaching management and FAQs about EdStem. The access requires a Franklin account.\n\n\n\nOn-Campus Course Schedule\nüìÖ Schedule Table - Live course schedule updated daily\nüìä Course Data (CSV) - Downloadable course information\n\n\n\nAnalytics Concept Review üìö\nüÉè Interactive Flip Cards - 60+ analytics concepts for study practice"
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "Analytics FAQ",
    "section": "",
    "text": "Q1: May I know more about the Business Analytics Program at Franklin University?\nOur Business Analytics Program has achieved national recognition, ranking #8 by TechGuide among online programs. Watch my comprehensive Program Orientation for detailed insights into curriculum, career outcomes, and program benefits.\nKey Program Highlights:\n\nIndustry-experienced faculty\nPractical, hands-on learning\nStrong job placement rates\nFlexible online format\nReal-world capstone projects\n\n\n\n\nQ2: Is Business Analytics a good fit for me?\nBusiness Analytics is ideal if you have:\n‚úÖ Intense curiosity to answer business questions\n‚úÖ Passion for exploring hidden patterns in data\n‚úÖ Enjoyment in solving new business problems\n‚úÖ Interest in data-driven decision making\n‚ùå Not recommended if you:\n\nPrefer routine, day-to-day work without variation\nAre not interested in data-based problem-solving\nDislike analytical thinking or quantitative reasoning\n\n\n\n\nQ3: Do I need a strong math background?\nShort answer: Not really. Here‚Äôs what you need to know:\nExample: Understanding Linear Regression\n\nYou need to understand that we‚Äôre finding the best line through data points\nWhy this line helps us make predictions about new data\nApplied approach: You can build effective models using software tools without knowing the mathematical derivations\nThe math behind it: Understanding calculus and linear algebra explains how the computer finds the best line, but you don‚Äôt need this to use regression effectively\n\nOur Philosophy: We teach analytics as an applied discipline. You learn to solve real business problems using proven methods and tools, rather than deriving mathematical formulas.\nMathematical Foundation Needed:\n\nEssential: Basic statistics understanding and logical thinking\nHelpful but not required: Linear algebra, calculus\nReality: You can successfully complete analytics projects and build your career without advanced mathematics\n\n\n\n\nQ4: Do I need strong programming skills?\nAbsolutely not! Our approach focuses on problem-solving using existing tools rather than software engineering.\nAnalytics Programming vs.¬†Software Engineering:\n\n‚úÖ Analytics Focus: Problem-solving with well-developed packages\n‚úÖ Tool Utilization: Leveraging R, Python, Tableau, SAS functions\n‚úÖ Student Success: Complete predictive analysis projects without writing loops\n‚ùå Not Required: Writing code like software engineers\n\nOur Philosophy: We teach you to be analytics problem-solvers, not programmers.\n\n\n\nQ5: What is Business Analytics and how does it differ from Data Analytics?\nBoth are applied Data Science fields, but with different emphases and technical depth:\nüè¢ Business Analytics \n\nPrimary Focus: Solving business problems using data\nGoal: Support decision-making and improve business outcomes\nQuestions: What happened? Why did this happen? What should we do?\nApproach: Business-oriented with moderate technical depth\nTools: Excel, SQL, Python, Power BI/Tableau, dashboards\nOutput: Actionable insights, KPIs, business recommendations\nAudience: Business users, managers, decision-makers\n\nüìä Data Analytics \n\nPrimary Focus: Understanding and exploring data in technical depth\nGoal: Generate insights, identify patterns, and build predictive models\nQuestions: What trends exist? What can we predict? How accurate is the model?\nApproach: Technical/methodological with higher statistical rigor\nTools: SQL, Python/R, advanced statistics, ML libraries, Jupyter notebooks\nOutput: Statistical reports, model predictions, pattern detection\nAudience: Analysts, technical teams, data scientists\n\nKey Difference: Business Analytics emphasizes applying data insights to business contexts for stakeholder decision-making, while Data Analytics focuses on technical precision and advanced statistical modeling for deeper analytical exploration.\nCommon Foundation: Both programs teach data manipulation, statistical analysis, and insight generation - the difference is in application focus and technical depth.\n\n\n\nQ6: What analytics tools should I learn?\nMost Important Principle: Ability to learn new tools &gt; mastery of specific tools\nüéØ Key Philosophy: Analytics tools evolve rapidly. The software popular today may be different in five years. Focus on methodology and adaptability rather than tool-specific expertise.\nMethodology &gt; Tools: Understanding the data mining process and algorithm intuition allows you to solve problems across platforms.\nRecommended Tool Exposure by Category:\nSpreadsheet Tools:\n\nExcel: Widely used for modeling, scenario analysis, and quick calculations\n\nDatabase Querying:\n\nSQL: Core skill for accessing and manipulating structured data (essential)\n\nData Visualization:\n\nPower BI: Common in business settings, integrates well with Microsoft ecosystem\nTableau: Strong in design and advanced visualizations\n\nProgramming Languages:\n\nPython: Most popular for analytics and data science; strong in automation, ML, and dashboard development\nR: Preferred in research and academia; excellent for statistical analysis and specialized visualizations\n\nWhy These Tools Matter:\n\nIndustry Demand: High job market requirements across sectors\nVersatility: Each serves different analytical needs and contexts\nLearning Value: Skills transfer between similar tools\nCareer Growth: Exposure to multiple tools increases opportunities\n\nStrategy: Gain exposure to tools from each category to position yourself effectively in the job market. The goal is understanding when and why to use each tool, not becoming an expert in all of them.\n\n\n\nQ7: What career opportunities are available after graduation?\nBelow is a snapshot of where graduates from B.S. in Analytics, M.S. in Business Analytics, and M.S. in Data Analytics programs typically land. Roles marked ‚òÖ often prefer‚Äîor sometimes require‚Äîa master‚Äôs degree.\nCareer Paths by Functional Area:\nBusiness & Strategy\n\nBusiness Analyst, Business Intelligence (BI) Analyst‚òÖ, Product Analyst\nNotes: Translate data into business actions; BI roles lean toward the M.S. in Business Analytics\n\nData & Reporting\n\nData Analyst, Reporting Analyst, Data Visualization Developer\nNotes: Core roles for B.S. grads; master‚Äôs degree can fast-track you to senior analyst positions\n\nMarketing & Customer Insights\n\nMarketing Analyst, Customer/CRM Analyst, Growth Analyst\nNotes: Heavy use of A/B testing and dashboarding; often require storytelling skills\n\nOperations & Supply Chain\n\nOperations Research Analyst‚òÖ, Supply Chain Analyst\nNotes: Optimization and simulation skills valued; many roles in manufacturing, logistics, and retail\n\nAdvanced Modeling & AI\n\nData Scientist‚òÖ, Machine Learning Engineer‚òÖ, Quantitative Analyst (FinTech)‚òÖ\nNotes: Strong fit for M.S. in Data Analytics; requires solid programming (Python/R) and statistics\n\nAnalytics Engineering\n\nAnalytics Engineer‚òÖ, Data Engineer (entry-level)\nNotes: Emerging bridge role: turns raw data into clean, analysis-ready datasets (dbt, SQL)\n\nGovernance & Risk\n\nRisk Analyst, Compliance Data Analyst, Fraud Analyst\nNotes: Growing demand in finance, healthcare, and government sectors\n\nIndustries Hiring Our Graduates:\n\nTechnology & Software\nFinance and Banking / FinTech\nHealthcare & Life Sciences\nRetail & E-commerce\nManufacturing & Supply Chain\nConsulting & Professional Services\nGovernment & Public Sector\nEnergy & Utilities (data-driven grid management)\nSports & Entertainment (ticketing, performance analytics)\n\nCareer Advancement Tip: Keep a portfolio (GitHub, Tableau Public, Power BI) showcasing projects that match your target roles‚Äîemployers increasingly treat it as a second r√©sum√©."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr.¬†Jiang ‚ÄòJohn‚Äô Li",
    "section": "",
    "text": "üìß Email Me\nüìÖ Book Meeting\n\n\n\nI serve as Program Chair for the M.S. in Business Analytics and B.S. in Analytics, and Lead Faculty for the M.S. in Data Analytics at Franklin University. My unique background combines industry experience as a Data Scientist in the insurance sector with academic research that includes a publication in Nature journal from my physics research at Ohio State University.\nCurrently, my research focuses on Learning Analytics, exploring how data can transform educational outcomes. I bring this dual perspective of industry practice and academic rigor to analytics education, helping students become effective problem-solvers in real-world contexts."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Dr.¬†Jiang ‚ÄòJohn‚Äô Li",
    "section": "",
    "text": "I serve as Program Chair for the M.S. in Business Analytics and B.S. in Analytics, and Lead Faculty for the M.S. in Data Analytics at Franklin University. My unique background combines industry experience as a Data Scientist in the insurance sector with academic research that includes a publication in Nature journal from my physics research at Ohio State University.\nCurrently, my research focuses on Learning Analytics, exploring how data can transform educational outcomes. I bring this dual perspective of industry practice and academic rigor to analytics education, helping students become effective problem-solvers in real-world contexts."
  },
  {
    "objectID": "index.html#teaching-philosophy",
    "href": "index.html#teaching-philosophy",
    "title": "Dr.¬†Jiang ‚ÄòJohn‚Äô Li",
    "section": "Teaching Philosophy",
    "text": "Teaching Philosophy\nRather than focusing on specific tools, I emphasize the ability to learn and adapt to new technologies. Analytics tools evolve rapidly, but fundamental methodologies remain stable. My students learn to be problem-solvers first, then apply appropriate tools to solve those problems.\nThis approach prepares students for the reality that whatever software is popular today may be different in five years, but strong analytical thinking and adaptability will always be valuable."
  },
  {
    "objectID": "index.html#connect-with-me",
    "href": "index.html#connect-with-me",
    "title": "Dr.¬†Jiang ‚ÄòJohn‚Äô Li",
    "section": "Connect With Me",
    "text": "Connect With Me\nWhether you‚Äôre interested in Franklin‚Äôs analytics programs, exploring research collaborations, or seeking analytics expertise, I‚Äôd love to hear from you.\n\nüìß Email Me üìÖ Book Meeting üíº LinkedIn"
  },
  {
    "objectID": "course.html",
    "href": "course.html",
    "title": "Course Offerings in Analytics Programs",
    "section": "",
    "text": "This course introduces the essential general programming concepts and techniques to analytics students. The goal is to equip the students with the necessary programming skill in analytics problem-solving. Topics include boolean, numbers, loops, function, debugging, Python‚Äôs specifics (such as NumPy, Pandas, Jupyter notebook), R‚Äôs specifics (such as list, data frame, factor, apply, RMarkdown), the process of data retrieving, cleaning, integrating, transforming, and enriching to support analytics.\nExams: There are proctored midterm and final exams.\nAnalytics Tools: Python (NumPy, Pandas), R (tidyverse)\n\n\n\n\nThis course introduces the fundamentals of Business and Data Analytics. Students will learn the fundamentals of business problem framing, data wrangling, descriptive and inferential statistics, data visualization, and data storytelling in analytics. Not open to students with credit for INFA 300.\nExams:: There is a proctored final exam.\nTools: Excel, R\n\n\n\n\nStudents will learn the basic concepts behind major machine learning algorithms, the essential steps for creating a typical machine learning model, the strengths and weaknesses of different algorithms, and the model evaluation using different performance metrics. Eventually students will be able to build a prediction model by machine learning algorithm using Python language. The differences between Java and Python will be reviewed. The common problems in practical machine learning exercises and their solutions also will be discussed.\nExams: There is a proctored final exam.\nAnalytics Tools: Python (scikit-learn, pandas), Jupyter Notebook\n\n\n\n\nThis course covers fundamental methods and widely-used technologies in data engineering. Topics include application programming interface (API), web scraping, Extract Transform Load (ETL), and analytics at-scale using PySpark.\nAnalytics Tools: Python, PySpark\n\n\n\n\nThis course covers advanced analytics topics, including big-data analytics using popular platforms, model interpretation strategies, simulations, optimizations, and analytics reporting and presentation methods. A discussion of ethical considerations for model evaluation is also included.\nAnalytics Tools: Python, R\n\n\n\n\nThis course introduces data analytics using Structured Query Language (SQL). Students will learn how to apply SQL in data exploration analysis and business problem-solving.\nAnalysis Tools: SQL\n\n\n\n\nThis course introduces the principles of analytics modeling. Students will learn exploratory data analytics, regression, classification, clustering, model interpretation, and model evaluation. Not open to students with credit for INFA 420.\nAnalyticsTools: R\n\n\n\n\n\n\n\nThis introductory course focuses on applying information technology to business strategies using databases. The student will gain a working knowledge of current database technology, including relational database concepts, database design, data extraction, and data warehousing while working with database applications.\nExams: There is a proctored final exam.\nAnalysis Tools: SQL"
  },
  {
    "objectID": "course.html#undergraduate-courses",
    "href": "course.html#undergraduate-courses",
    "title": "Course Offerings in Analytics Programs",
    "section": "",
    "text": "This course introduces the essential general programming concepts and techniques to analytics students. The goal is to equip the students with the necessary programming skill in analytics problem-solving. Topics include boolean, numbers, loops, function, debugging, Python‚Äôs specifics (such as NumPy, Pandas, Jupyter notebook), R‚Äôs specifics (such as list, data frame, factor, apply, RMarkdown), the process of data retrieving, cleaning, integrating, transforming, and enriching to support analytics.\nExams: There are proctored midterm and final exams.\nAnalytics Tools: Python (NumPy, Pandas), R (tidyverse)\n\n\n\n\nThis course introduces the fundamentals of Business and Data Analytics. Students will learn the fundamentals of business problem framing, data wrangling, descriptive and inferential statistics, data visualization, and data storytelling in analytics. Not open to students with credit for INFA 300.\nExams:: There is a proctored final exam.\nTools: Excel, R\n\n\n\n\nStudents will learn the basic concepts behind major machine learning algorithms, the essential steps for creating a typical machine learning model, the strengths and weaknesses of different algorithms, and the model evaluation using different performance metrics. Eventually students will be able to build a prediction model by machine learning algorithm using Python language. The differences between Java and Python will be reviewed. The common problems in practical machine learning exercises and their solutions also will be discussed.\nExams: There is a proctored final exam.\nAnalytics Tools: Python (scikit-learn, pandas), Jupyter Notebook\n\n\n\n\nThis course covers fundamental methods and widely-used technologies in data engineering. Topics include application programming interface (API), web scraping, Extract Transform Load (ETL), and analytics at-scale using PySpark.\nAnalytics Tools: Python, PySpark\n\n\n\n\nThis course covers advanced analytics topics, including big-data analytics using popular platforms, model interpretation strategies, simulations, optimizations, and analytics reporting and presentation methods. A discussion of ethical considerations for model evaluation is also included.\nAnalytics Tools: Python, R\n\n\n\n\nThis course introduces data analytics using Structured Query Language (SQL). Students will learn how to apply SQL in data exploration analysis and business problem-solving.\nAnalysis Tools: SQL\n\n\n\n\nThis course introduces the principles of analytics modeling. Students will learn exploratory data analytics, regression, classification, clustering, model interpretation, and model evaluation. Not open to students with credit for INFA 420.\nAnalyticsTools: R\n\n\n\n\n\n\n\nThis introductory course focuses on applying information technology to business strategies using databases. The student will gain a working knowledge of current database technology, including relational database concepts, database design, data extraction, and data warehousing while working with database applications.\nExams: There is a proctored final exam.\nAnalysis Tools: SQL"
  },
  {
    "objectID": "course.html#graduate-courses",
    "href": "course.html#graduate-courses",
    "title": "Course Offerings in Analytics Programs",
    "section": "üéØ Graduate Courses",
    "text": "üéØ Graduate Courses\n\nDr.¬†Li as Lead Faculty\n\nDATA 610: Big Data Analytics and Data Mining\nThis course explores data mining methods and tools, examines the issues in the analytical analysis of massive datasets, and unstructured data. Students will learn the concepts and techniques to discover the patterns in large datasets, which support organizational decision making.\nExams: There are proctored midterm and final exams.\nAnalytics Tools: Python (NumPy, Pandas), Jupyter Notebook\n\n\n\nDATA 630: Applied Database Management\nThis course teaches data management from an applied perspective. The topics include fundamentals of database management systems, structured query language (SQL) for data analytics, relational database design, and data warehousing.\nExams: There are proctored midterm and final exams.\nAnalytics Tools: SQL\n\n\n\nDATA 600: Modern Tools for Stat Analysis\nThis course offers an in-depth exploration of modern statistical analysis tools, focusing on the integration of modern analytics tools enhanced by artificial intelligence techniques. The goal is to equip students with advanced skills in using these contemporary analytics tools for statistical descriptive data analysis and effective problem-solving across various analytical contexts.\nExams: There are proctored midterm and final exams.\nAnalytics Tools: Excel, Python (NumPy, Pandas), R (tidyverse), AI\n\n\n\nDATA 611: Applied Machine Learning\nThis course explores two main areas of machine learning: supervised and unsupervised. Topics include linear and logistic regression, probabilistic inference, Support Vector Machines, Artificial Neural Networks, clustering, dimensionality reduction, and programming.\nAnalytics Tools: Python, scikit-learn, Google Colab\n\n\n\nBUSA 603: Marketing Management & Analytics\nThis course covers the application of analytics tools, techniques, strategies and methods to marketing management. Students learn to analyze market data, enabling management decisions to be based on data-driven facts and customer insights. Using marketing analytics tools to model scenarios, students learn how organizations can measure returns on investment relative to their marketing efforts, drive performance and strengthen the effectiveness of its campaigns.\nExams: There is a proctored final exam.\nAnalytics Tools: Python, Google Analytics\n\n\n\nBUSA 695: Capstone in Business Analytics\nStudents demonstrate an integrative knowledge of analytics in this course by developing a project plan to implement analytics for an important function, unit or department of the organization chosen in the Business Analytics strategy course. Students apply analytics tools, techniques, methods and strategies to drive business outcomes for the chosen company using relevant project-based methodologies. The course allows students to develop a professional portfolio that will highlight the work completed throughout the degree program. This may serve as a relevant employability resource.\nTools\nStudents select from tools covered in the program, including Excel, Tableau, Python, R, etc.\n\n\n\n\nOther Key Offerings\n\nBUSA 604: Financial Decision Modeling\nThis course is built on the theory, strategy and practice of financial management, emphasizing computer-based modeling and forecasting. Students learn to model financial scenarios using analytics tools. The impact of financial decisions relative to financial statements analysis, cash budgeting, cost of capital determination, capital budgeting, and capital structure choices are covered. A variety of techniques, such as sensitivity and scenario analysis, optimization methods, Monte Carlo simulation, and regression analysis are also covered.\nAnalytics Tools: Excel\n\n\n\nBUSA 605: Business Analytics Strategy\nThis course allows students to apply the fundamental analytics principles in the development of an analytics strategy for a business of choice. Given a range of options, students will research and choose the best analytics strategy under given scenarios. The course uses case studies, employing a problem and project-based approach to the development of a strategy.\nAnalytics Tools: Selected by students if needed."
  },
  {
    "objectID": "post.html",
    "href": "post.html",
    "title": "Posts",
    "section": "",
    "text": "Educational Content\n\nIntroduction to Regularization\nAnalytics Job Application\nIndeed.com Analytics Job Listing\nPopular Analytics Tools\nCommonly-used R & Python Scripts for Data Wrangling\nPopularity of Analytics Tools in Job Listings\n\n\n\nLinkedIn\n\nCapstone Success: Congrats to M.S. in Business Analytics & Health Informatics Students!\nOhio Tech Summit 2024 - AI in Higher Education\nCelebrating DataFest 2025 Winners at Franklin University\nASA DataFest 2025 Analytics Competition\nCPT Workshop - Career Development for International Students\nIndustry Collaboration and Student Success\nWork-Based Learning in Business Analytics\nData Strategy and Analytics in Business Decision Making\nFranklin University Technology Programs Excellence\nDirector of On-Campus Technology Programs Announcement\nStudent Research and Innovation Showcase\nFIE 2024 Conference - STEM Education Innovation\nStudent Achievement and Community Engagement\nAI and Machine Learning Community Leadership\nAI Python for Beginners - Programming Made Accessible\nMeet Advisory Board Member\nDataFest 2024\nFranklin University‚Äôs Master‚Äôs in Business Analytics program has been ranked NO.8 by TechGuide\nNew B.S. in Analytics Program\nDataConnect\nMaster of Science in Analytics Degree from Georgia Tech\nFranklin University‚Äôs STEM scholarship\nData Science Prompts\nIntroduction to Regularization\nHeilmeier‚Äôs Questions\nSemantic Layer Summit\nUseful Excel Functions\nInclusive Pedagogy\nSalary Information in the Industry\nOpenAI‚Äôs Response to ‚Äúhow to learn business analytics?‚Äù\nCake from My Students\nJob Listing Count On U.S. Map\nOhio First Scholarship\nCompanies don‚Äôt have datasets waiting for you\nDataFest 2022 Winners\nCommon Mistates of SQL JOIN\nAn Intuitive Visualization of SQL JOIN\nMcGraw Hill Business Analytics Summit 2022\nTeach International Students from India\nConvert English Language to Python\nCommonly-used Analytics Tools\nDATA 300: Introduction to Analytics\nData Science in 2021\nEd Discussion Tool\nCorrelation vs.¬†causation\nProduct Analyst Role\nA/B Testing\nFree courses in LinkedIn Learning\nRedesign DATA 610\nAWS Cloud\nDataFest 2021\nDomain Knowledge\nSQL Data Duplication\nRStudio::global 2021\nAnalytics Reporting\nKey Data Science Concepts for Interview\nWelcome Dr.¬†Vesselinov\nEssential SQL Concepts\nHighlighted Analtyics Skills\nAWS Big Data Event\nConfidence Interval\nSuggestion to students: get hands dirty\nData Cleaning\nSuggestion to students: be a problem solver\nSuggestion to students: continue being curious\nData Science Thinking: a case study\n\n\nPowered by Quarto"
  },
  {
    "objectID": "publication.html",
    "href": "publication.html",
    "title": "Publications",
    "section": "",
    "text": "Identifying Interpretable Features Impacting Nontraditional Undergraduate Computer Science Student Retention, Frontier In Education (FIE) 2024 Conference. link\nLearning Analytics Finds That A Shared Course May Improve Technology Students Retention, Journal of Computing Sciences in Colleges, April 2023. link\nDynamics and mechanism of repair of ultraviolet-induced (6‚Äì4) photoproduct by photolyase, Nature, August 2010. link"
  },
  {
    "objectID": "teach/ai-workflow/index.html",
    "href": "teach/ai-workflow/index.html",
    "title": "A Practical AI-Augmented Analytics Workflow",
    "section": "",
    "text": "Objective: This segment will close the ‚Äúprompting gap‚Äù that many new users experience with AI. By the end of this segment, you will understand the framework for conducting a structured, effective AI dialogue, moving from simple questions to a sophisticated, iterative conversation that produces high-quality analytical insights.\n\n\nThe most common mistake when first using a generative AI for data analysis is to treat it like a search engine. We are used to typing a few keywords into Google and getting a list of links. This is a search for a pre-existing answer.\nAn AI chatbot is different. It is not a library of answers; it is a reasoning engine. You are not ‚Äúfinding‚Äù an analysis; you are commissioning one. Your role is not to be a searcher, but a director. You must provide clear, specific instructions, just as you would to a junior data analyst on your team.\n\nA search query is a request for information.\nA prompt is a set of instructions for a task.\n\n\n\n\nA powerful initial prompt is the foundation of a successful AI dialogue. It gives the AI all the information it needs to perform the task correctly on the first try. A great way to structure your prompts is with the P-C-T-F Framework.\n\nBad Example (Too General): A prompt like ‚ÄúAnalyze my Superstore data‚Äù is too vague. The AI doesn‚Äôt know your goal, who you are, or what to look for. It will likely give you a very generic summary of the file (e.g., ‚ÄúThis file contains 21 columns including Sales and Profit‚Ä¶‚Äù) which is not a useful analysis.\nGood Example (Specific & Actionable): Let‚Äôs build a prompt using the P-C-T-F framework.\n\nPersona: ‚ÄúAct as a business data analyst.‚Äù\nContext: ‚ÄúThe goal is to prepare a summary for a marketing meeting to discuss regional performance.‚Äù\nTask: ‚ÄúUsing the Orders sheet from the attached Superstore.xlsx file, calculate the total profit for each Region.‚Äù\nFormat: ‚ÄúPresent the result as a simple markdown table, sorted from highest to lowest profit.‚Äù\n\n\nThis good prompt tells the AI its role, the business goal, the exact task to perform, and how to structure the output, leading to a much more useful and immediate result.\n\n\n\nA great initial prompt is just the start of the conversation. The real power of AI-augmented analysis comes from the follow-up dialogue, where you use your own critical thinking to guide the AI to deeper insights. A productive conversation follows a natural, three-step flow.\nLet‚Äôs assume our initial prompt was: ‚ÄúAct as a business analyst. Using the Orders sheet in the attached data, what are the top 3 product categories by total profit?‚Äù\nStep 1: Clarify & Drill Down First, make sure you understand the initial response and get more detail on the most interesting part. This is where you move from a high-level summary to a specific area of interest.\n\nGoal: To focus the analysis on a key finding.\nExample Follow-up Prompt: ‚ÄúThat‚Äôs helpful. For the ‚ÄòTechnology‚Äô category only, show me the profit by sub-category.‚Äù\n\nStep 2: Question & Hypothesize Next, use your analytical mind to ask ‚Äúwhy?‚Äù This prompts the AI to connect different data points to suggest potential causes for a finding.\n\nGoal: To move from observing ‚Äúwhat‚Äù is happening to exploring ‚Äúwhy‚Äù it might be happening.\nExample Follow-up Prompt: ‚ÄúWhy is ‚ÄòFurniture‚Äô profit so low? Compare its average discount to other categories.‚Äù\n\nStep 3: Challenge & Refine Finally, act as the director. Challenge the AI‚Äôs initial approach and ask it to refine the analysis based on your own critical thinking. This is the most advanced step, where you guide the AI to a better, more robust analysis.\n\nGoal: To improve the quality and relevance of the analysis itself.\nExample Follow-up Prompt: ‚ÄúIs total profit the best metric here? Redo the analysis using profit margin (Profit / Sales) instead and tell me what changes.‚Äù\n\nBy following this Clarify -&gt; Question -&gt; Challenge model, you can transform a simple Q&A session into a powerful analytical dialogue that uncovers deep and actionable insights."
  },
  {
    "objectID": "teach/ai-workflow/index.html#how-to-direct-your-ai-analyst---the-art-of-the-prompt",
    "href": "teach/ai-workflow/index.html#how-to-direct-your-ai-analyst---the-art-of-the-prompt",
    "title": "A Practical AI-Augmented Analytics Workflow",
    "section": "",
    "text": "Objective: This segment will close the ‚Äúprompting gap‚Äù that many new users experience with AI. By the end of this segment, you will understand the framework for conducting a structured, effective AI dialogue, moving from simple questions to a sophisticated, iterative conversation that produces high-quality analytical insights.\n\n\nThe most common mistake when first using a generative AI for data analysis is to treat it like a search engine. We are used to typing a few keywords into Google and getting a list of links. This is a search for a pre-existing answer.\nAn AI chatbot is different. It is not a library of answers; it is a reasoning engine. You are not ‚Äúfinding‚Äù an analysis; you are commissioning one. Your role is not to be a searcher, but a director. You must provide clear, specific instructions, just as you would to a junior data analyst on your team.\n\nA search query is a request for information.\nA prompt is a set of instructions for a task.\n\n\n\n\nA powerful initial prompt is the foundation of a successful AI dialogue. It gives the AI all the information it needs to perform the task correctly on the first try. A great way to structure your prompts is with the P-C-T-F Framework.\n\nBad Example (Too General): A prompt like ‚ÄúAnalyze my Superstore data‚Äù is too vague. The AI doesn‚Äôt know your goal, who you are, or what to look for. It will likely give you a very generic summary of the file (e.g., ‚ÄúThis file contains 21 columns including Sales and Profit‚Ä¶‚Äù) which is not a useful analysis.\nGood Example (Specific & Actionable): Let‚Äôs build a prompt using the P-C-T-F framework.\n\nPersona: ‚ÄúAct as a business data analyst.‚Äù\nContext: ‚ÄúThe goal is to prepare a summary for a marketing meeting to discuss regional performance.‚Äù\nTask: ‚ÄúUsing the Orders sheet from the attached Superstore.xlsx file, calculate the total profit for each Region.‚Äù\nFormat: ‚ÄúPresent the result as a simple markdown table, sorted from highest to lowest profit.‚Äù\n\n\nThis good prompt tells the AI its role, the business goal, the exact task to perform, and how to structure the output, leading to a much more useful and immediate result.\n\n\n\nA great initial prompt is just the start of the conversation. The real power of AI-augmented analysis comes from the follow-up dialogue, where you use your own critical thinking to guide the AI to deeper insights. A productive conversation follows a natural, three-step flow.\nLet‚Äôs assume our initial prompt was: ‚ÄúAct as a business analyst. Using the Orders sheet in the attached data, what are the top 3 product categories by total profit?‚Äù\nStep 1: Clarify & Drill Down First, make sure you understand the initial response and get more detail on the most interesting part. This is where you move from a high-level summary to a specific area of interest.\n\nGoal: To focus the analysis on a key finding.\nExample Follow-up Prompt: ‚ÄúThat‚Äôs helpful. For the ‚ÄòTechnology‚Äô category only, show me the profit by sub-category.‚Äù\n\nStep 2: Question & Hypothesize Next, use your analytical mind to ask ‚Äúwhy?‚Äù This prompts the AI to connect different data points to suggest potential causes for a finding.\n\nGoal: To move from observing ‚Äúwhat‚Äù is happening to exploring ‚Äúwhy‚Äù it might be happening.\nExample Follow-up Prompt: ‚ÄúWhy is ‚ÄòFurniture‚Äô profit so low? Compare its average discount to other categories.‚Äù\n\nStep 3: Challenge & Refine Finally, act as the director. Challenge the AI‚Äôs initial approach and ask it to refine the analysis based on your own critical thinking. This is the most advanced step, where you guide the AI to a better, more robust analysis.\n\nGoal: To improve the quality and relevance of the analysis itself.\nExample Follow-up Prompt: ‚ÄúIs total profit the best metric here? Redo the analysis using profit margin (Profit / Sales) instead and tell me what changes.‚Äù\n\nBy following this Clarify -&gt; Question -&gt; Challenge model, you can transform a simple Q&A session into a powerful analytical dialogue that uncovers deep and actionable insights."
  },
  {
    "objectID": "teach/ai-workflow/index.html#introduction-to-the-ai-chatbot",
    "href": "teach/ai-workflow/index.html#introduction-to-the-ai-chatbot",
    "title": "A Practical AI-Augmented Analytics Workflow",
    "section": "2 Introduction to the AI Chatbot",
    "text": "2 Introduction to the AI Chatbot\nObjective: This segment provides a hands-on walkthrough of the AI chatbot interface we will use for our analysis. By the end of this segment, you will know how to access the tool, upload your data, and begin a well-structured analytical dialogue using the P-C-T-F framework.\nTool: We will be using the free version of Google Gemini for this tutorial and for your final project.\n\n2.0.1 Part 1: Accessing and Setting Up Your Environment\nFirst, we need to open the tool and prepare it for our analysis.\n\nNavigate to the Website: Open a web browser and go to the Google Gemini website: gemini.google.com\nSign In: If you are not already logged in, sign in with your Google account. You will be presented with the main chat interface. It‚Äôs a clean page with a text box at the bottom where you will type your prompts.\nStart a New Chat: It‚Äôs a best practice to start a new chat for each new project or distinct analysis. This keeps your conversations organized. If you have old conversations open, you can start a new one by clicking the ‚Äú+ New chat‚Äù button, usually located in the top-left corner.\n\n\n\n2.0.2 Part 2: Uploading Your Data File\nNow, we need to provide the AI with the data it will analyze.\n\nLocate the Upload Button: At the bottom of the screen, in the text box where you type your prompts, you will see several icons. Look for the paperclip icon (üìé). This is the ‚ÄúAttach files‚Äù or ‚ÄúUpload‚Äù button.\nSelect the File: Click the paperclip icon. A dialog box will open, allowing you to browse your computer for a file. Navigate to where you have saved your Superstore.xlsx file and select it.\nConfirm the Upload: After you select the file, Gemini will process it. You will see the file appear just above the text box, confirming that it is ready for analysis. The AI may also give you a brief message like, ‚ÄúSuperstore.xlsx has been uploaded. What would you like to know about this file?‚Äù\n\nYour environment is now set up. You have an active chat session, and the AI has access to your dataset.\n\n\n2.0.3 Part 3: Asking Your First Analytical Question\nThis is where we put the theory from Segment 1 into practice. We will not ask a vague question. Instead, we will use the full P-C-T-F framework to commission a specific piece of analysis.\n\nConstruct Your Prompt: In the text box, you will now type your well-structured prompt. Let‚Äôs use the same ‚ÄúGood Example‚Äù from the previous segment. Type the following into the prompt box:\n\nAct as a business data analyst. The goal is to prepare a summary for a marketing meeting to discuss regional performance. Using the Orders sheet from the attached Superstore.xlsx file, calculate the total profit for each Region. Present the result as a simple markdown table, sorted from highest to lowest profit.\n\nSend the Prompt: Press Enter or click the ‚ÄúSend‚Äù button.\nReview the Output: Gemini will now perform the analysis and should provide an output that matches your request perfectly: a clean, sorted markdown table showing the total profit for each of the four regions.\n\n\n\n2.0.4 Part 4: Continuing the Dialogue with Follow-up Questions\nA great initial answer is just the start. Now, we apply the three-step dialogue model from Segment 1 to dig deeper.\n\nClarify & Drill Down: The initial output shows that the ‚ÄúWest‚Äù region is the most profitable. A good analyst would immediately want to know what‚Äôs driving that success. Let‚Äôs ask a follow-up question to get more detail.\n\nPro Tip: Re-anchoring Your AI: Sometimes, in a long conversation, an AI can ‚Äúlose context‚Äù and forget about the file you uploaded. To prevent this, it‚Äôs a best practice to gently remind the AI of your data source in your follow-up prompts.\nFollow-up Prompt: &gt; That‚Äôs a great start. Now, using the attached Superstore.xlsx file, show me the total profit by Sub-Category for the ‚ÄòWest‚Äô region only and present it as a sorted markdown table.\n\nQuestion & Hypothesize: The AI will now show you that within the West region, ‚ÄúCopiers‚Äù and ‚ÄúBinders‚Äù are highly profitable. But you might also see that ‚ÄúTables‚Äù are losing money. This leads to a ‚Äúwhy‚Äù question.\n\nFollow-up Prompt: &gt; Interesting. Why are ‚ÄòTables‚Äô so unprofitable in the West region? Compare the average Discount for ‚ÄòTables‚Äô in the West to the average discount for ‚ÄòTables‚Äô in other regions.\n\nChallenge & Refine: The AI might give you a table showing that the average discount for ‚ÄòTables‚Äô is around 32% and confidently state that this is the ‚Äúprimary driver.‚Äù This is where you, the human analyst, must apply your critical thinking and challenge the AI‚Äôs approach by maintaining the focus of your investigation.\n\nFollow-up Prompt: &gt; You‚Äôve shown me the impact of discounts, but is that the only factor? Redo the analysis, but this time show me both the average Discount and the average Shipping Cost for ‚ÄòTables‚Äô in the West region compared to other sub-categories in the West region. This will give us a more complete picture.\nThe Analyst‚Äôs Role: This final step is the most important. The AI is excellent at finding correlations (the ‚Äúwhat‚Äù), but your job is to use your business knowledge to question its conclusions and guide it to a more complete analysis (the ‚Äúso what?‚Äù). Never blindly trust an AI‚Äôs first conclusion. Use its output as a hypothesis, and then use your own critical judgment to decide what to ask next.\n\n\nThis iterative process of prompting, receiving a hypothesis, and then using your own judgment to challenge and refine the analysis is the core of effective and responsible AI-augmented analysis."
  },
  {
    "objectID": "teach/ai-workflow/index.html#introduction-to-the-analysts-lab---notebooks",
    "href": "teach/ai-workflow/index.html#introduction-to-the-analysts-lab---notebooks",
    "title": "A Practical AI-Augmented Analytics Workflow",
    "section": "3 Introduction to the Analyst‚Äôs Lab - Notebooks",
    "text": "3 Introduction to the Analyst‚Äôs Lab - Notebooks\nObjective: In the previous segment, you used an AI chatbot to perform a quick, exploratory analysis. That process is excellent for brainstorming and getting initial ideas. However, for a formal project, you need a way to present your work that is clean, professional, and reproducible. This is where notebooks come in. By the end of this segment, you will understand what a notebook is and how to use its basic components.\nTool: We will be using Google Colab, a free, cloud-based notebook environment.\n\n3.0.1 Part 1: What is a Notebook? The Analyst‚Äôs Lab Notebook\nThink of a Google Colab notebook as a digital lab notebook for a data analyst. It‚Äôs a single, interactive document where you can combine everything related to your analysis in one place:\n\nYour notes and narrative: Explanations of your goals, methods, and findings.\nYour live, runnable code: The actual Python code you use to perform the analysis.\nYour results: The outputs from your code, including tables, statistics, and data visualizations.\n\nThis is the professional standard for data analysis because it makes your work transparent and reproducible. Anyone can open your notebook, read your thought process, run your code, and get the exact same results.\nGetting Started:\n\nNavigate to colab.research.google.com.\nSign in with your Google account.\nAn ‚ÄúOpen notebook‚Äù dialog box will appear. This box allows you to open recent files, upload a notebook, or create a new one. For now, you can simply click the ‚ÄúNew notebook‚Äù link at the bottom of this box to get started.\nIf you have already closed that box, you can always create a new notebook by going to the File menu in the top-left corner and selecting New notebook.\n\n\n\n3.0.2 Part 2: The Two Building Blocks - Code Cells and Text Cells\nA notebook is built from two fundamental types of cells. You can add new cells using the ‚Äú+ Code‚Äù and ‚Äú+ Text‚Äù buttons at the top of the page.\n1. Code Cells This is where you write and run your Python code.\n\nAppearance: A code cell has a light gray background and a ‚Äúplay‚Äù button (‚ñ∂Ô∏è) to its left.\nAction: Type a simple line of Python code into the cell, like print(\"Hello, World!\").\nExecution: Click the play button. The code will run on Google‚Äôs servers, and the output (Hello, World!) will appear directly below the cell.\n\n2. Text Cells (Markdown) This is where you write your narrative, add headings, and explain your work. Text cells use a simple formatting language called Markdown.\n\nAction: Click the ‚Äú+ Text‚Äù button to add a text cell. You will see a split view: the left side is the editor where you type your Markdown, and the right side shows a live preview of the rendered text.\nFormatting with Markdown (The Basics):\n\nTo create a large heading, start a line with a single hashtag (#). Example: # My Analysis Title\nTo create a smaller subheading, use more hashtags. Example: ## Step 1: Data Cleaning\nTo create a bulleted list, start each line with an asterisk (*). Example: * First item\n\nViewing and Editing: When you click out of a text cell, it will show the final, beautifully rendered text. To edit it again, simply double-click on the text, and the split-screen editor will reappear.\n\n\n\n3.0.3 Part 3: The Analyst‚Äôs Workflow in a Notebook\nA professional analysis notebook tells a story. The best practice is to alternate between text and code cells to guide your reader through your work.\n\nStart with a Text Cell: Add a text cell at the top and use Markdown to give your analysis a title and a brief introduction explaining your goal.\nAdd a Code Cell: Below your introduction, add a code cell to perform the first step of your analysis (e.g., loading the data).\nAdd another Text Cell: Below the code‚Äôs output, add another text cell to explain the results or introduce the next step.\n\nBy following this simple pattern, you can create a clean, easy-to-follow report that combines your narrative and your code in a single, powerful document. In the next segment, we will combine everything we‚Äôve learned to demonstrate the full workflow, from AI chatbot to a finished notebook."
  },
  {
    "objectID": "teach/ai-workflow/index.html#the-full-workflow---from-ai-chatbot-to-notebook",
    "href": "teach/ai-workflow/index.html#the-full-workflow---from-ai-chatbot-to-notebook",
    "title": "A Practical AI-Augmented Analytics Workflow",
    "section": "4 The Full Workflow - From AI Chatbot to Notebook",
    "text": "4 The Full Workflow - From AI Chatbot to Notebook\nObjective: In this segment, we will put everything together. You will see a complete, end-to-end demonstration of the AI-augmented workflow, moving from an initial question in an AI chatbot to a final, reproducible analysis in a notebook. This is the exact workflow you will use to complete your final project.\n\n4.0.1 Part 1: The Exploratory Dialogue (in the AI Chatbot)\nOur workflow begins with a conversation. The goal here is not to produce a final report, but to explore the data, test ideas, and generate the initial code.\n\nStart in your AI Chatbot (e.g., Google Gemini) with the Superstore.xlsx file uploaded.\nUse a Powerful Initial Prompt: Let‚Äôs use a task that should be familiar from your Module 1 homework. We will ask the AI to calculate the return rate by region.\n\nAct as a business data analyst. Using the Orders and Returns sheets from the attached Superstore.xlsx file, perform the following steps:\n\n\n\nClean the Returns data by removing duplicate Order IDs.\n\n\nMerge the cleaned Returns data with the Orders data to identify which orders were returned.\n\n\nCalculate the return rate for each Region.\n\n\nPresent the final return rates in a simple markdown table.\n\n\nCritically Evaluate the AI‚Äôs Methodology: The AI will likely give you the correct answer, but it may have made an intelligent assumption without telling you. For example, it might have correctly used the count of unique Order IDs for the total number of sales, rather than the total number of rows (since one order can have multiple rows). A good analyst must make this transparent. This is a perfect time to use a ‚ÄúChallenge & Refine‚Äù follow-up prompt.\n\nFollow-up Prompt to Verify Methodology: &gt; ‚ÄúThis looks correct, but to ensure I understand your work, please explain exactly how you calculated the denominator (the total number of sales) for the return rate. Did you use the total row count from the Orders sheet, or the count of unique Order IDs? Explain why you chose that method.‚Äù This step is crucial. It forces the AI to reveal its logic, making your analysis transparent and confirming that the business logic is sound.\n\n\n\n\n4.0.2 Part 2: The Hand-off - From Dialogue to Code\nOnce your exploratory dialogue has produced a correct and well-understood analysis, it‚Äôs time to make it reproducible.\n\nAsk for the Code: The final step in your AI dialogue is to ask for the complete, clean code that produced the final result.\n\nThis is perfect. Now, show me the complete, single block of Python code you used to perform this entire analysis, from loading the files to calculating the final return rates based on unique Order IDs.\n\nCopy the Code: The AI will generate a block of Python code. Copy this entire block to your clipboard.\n\n\n\n4.0.3 Part 3: The Formal Report (in the Notebook)\nNow, we move from the exploratory environment of the chatbot to the formal, professional environment of a notebook (e.g., Google Colab).\n\nCreate a New Notebook: Open Google Colab and create a new notebook. Give it a descriptive name like ‚ÄúReturn Rate Analysis‚Äù.\nStart with a Narrative: The first step in a professional report is to explain what you are doing.\n\nAdd a Text (Markdown) cell at the top.\nWrite a clear title and a brief introduction. For example:\n# Analysis of Return Rates by Region This analysis investigates the product return rates across different sales regions for the Global Superstore. The goal is to identify which region has the highest rate of returns.\n\nUpload Your Data to the Notebook: Your notebook needs access to the data file.\n\nOn the left side of your Colab screen, click the folder icon to open the file browser.\nClick the ‚ÄúUpload to session storage‚Äù button (it looks like a page with an arrow pointing up).\nSelect the Superstore.xlsx file from your computer. You will see it appear in the file browser.\n\nBuild Your Analysis Step-by-Step:\n\nInstead of pasting the entire script into one cell, it is a best practice to break it into logical chunks in separate code cells. This makes your analysis easier to read, document, and debug.\nStep 1: Imports and Data Loading: In the first code cell, paste only the lines for importing libraries and loading the data. Run it to make sure the data loads correctly.\nStep 2: Document Your Process: In a new text cell, explain the next step. For example: ‚ÄúNow that the data is loaded, the next step is to clean the Returns data by removing any duplicate Order IDs.‚Äù\nStep 3: Add More Code: In a new code cell, paste the line of code that performs the data cleaning. Run it.\nContinue this pattern: Continue breaking the AI-generated script into logical steps. After each code cell, you should add a text cell to explain what you did, interpret the results, or introduce the next step in your analysis. This creates a clear, professional narrative.\n\nTroubleshooting and Debugging:\n\nWhat if you get an error? This is a normal part of the process! By breaking the code into cells, you know exactly which step failed.\nThe Debugging Workflow: If a cell produces an error, copy both the code from that cell and the full error message. Paste them back into your AI chatbot and ask: ‚ÄúI ran this code and got the following error. Can you explain what went wrong and help me fix it?‚Äù This teaches you to use the AI not just for creating code, but for fixing it as well.\n\n\nKey Takeaway: You have now successfully completed the full AI-augmented workflow. You used the AI chatbot for its speed and brainstorming capabilities, but you used your own critical thinking to verify its methods. You then used the notebook to create a final, documented, and reproducible report, applying debugging skills to ensure the code works perfectly. This process‚ÄîDialogue ‚Üí Verification ‚Üí Code ‚Üí Debug ‚Üí Documented Notebook‚Äîis a powerful and professional way to conduct data analysis!"
  },
  {
    "objectID": "teach/ai-workflow/index.html#appendix-data-and-course-resources",
    "href": "teach/ai-workflow/index.html#appendix-data-and-course-resources",
    "title": "A Practical AI-Augmented Analytics Workflow",
    "section": "5 Appendix: Data and Course Resources",
    "text": "5 Appendix: Data and Course Resources\n\n5.1 Sample Data\nThe tutorial uses the Superstore dataset, a sample dataset commonly used for learning data analysis:\nüìä Download Superstore.xlsx - Sample retail dataset for practice\nCitation: Tableau Software. (2021). Sample - Superstore.xls. Retrieved from https://www.tableau.com\n\n\n5.2 Data Dictionary\n\nComplete field descriptions for the Superstore dataset used in this tutorial.\n\n\n\n\n\n\n\nField Name\nType\nDescription\n\n\n\n\nOrder ID\nCategorical\nUnique identifier for each customer order (e.g., CA-2016-152156)\n\n\nOrder Date\nCategorical\nCalendar date the order was placed\n\n\nShip Mode\nCategorical\nShipping method (e.g., First Class, Standard Class)\n\n\nCustomer ID\nCategorical\nUnique ID for each customer\n\n\nCustomer Name\nCategorical\nFull name of the customer\n\n\nSegment\nCategorical\nMarket segment: Consumer, Corporate, or Home Office\n\n\nCity\nCategorical\nCity where the order was delivered\n\n\nState\nCategorical\nU.S. state of delivery\n\n\nRegion\nCategorical\nOne of four U.S. regions: East, West, Central, South\n\n\nCategory\nCategorical\nMain product category: Furniture, Office Supplies, Technology\n\n\nSub-Category\nCategorical\nMore specific product type (e.g., Binders, Phones)\n\n\nProduct Name\nCategorical\nFull name of the product\n\n\nSales\nNumerical (Continuous)\nTotal sales amount for the line item\n\n\nQuantity\nNumerical (Continuous)\nNumber of units sold\n\n\nDiscount\nNumerical (Continuous)\nDiscount applied to the line item (0 to 1)\n\n\nProfit\nNumerical (Continuous)\nProfit earned on the line item (can be negative)"
  }
]