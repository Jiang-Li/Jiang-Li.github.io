---
title: "Script"
output:
  html_document:
    toc_float: false

# output: html_notebook
---

```{r setup, include=F} 
library(tidyverse)
```  

I often use R and Python simultaneously. To make the switch between them easier, I built a list of the commonly-used script for a quick reference.  First, to demonstrate the code, simulate a sample data set with missing values and duplicated values.   

```{r}
set.seed(1)
N <- 1000
df <- data.frame(
  dimension1 = sample(c("I", "II", "III"), N, replace = T),
  dimension2 = sample(c("A", "B", "C"), N, replace = T),
  measure1 = sample(1:10, N, replace = T),
  measure2 = sample(1:10, N, replace = T)
)

df <- as.data.frame(lapply(df, 
                       function(r) 
                         r[sample(c(TRUE, NA), 
                                  prob = c(0.85, 0.15), 
                                  size = length(r), 
                                  replace = TRUE)]
                       )
                    )

head(df)
```

Then, in order to share the data in Python, save the data in a feather file.
```{r}
library(feather)
write_feather(df, "sample_data.feather")
```


## Rows and Columns

### R



```{r}
# row count
nrow(df) 

# column count
ncol(df)

# shape
dim(df)

# column names
names(df) 

# data type by column
lapply(df, class) 
```


### Python
```{python, eval=T}
import pandas as pd
df = pd.read_feather("sample_data.feather")

# row count
df.shape[0]
```

```{python, eval=T}
# column count
df.shape[1]
```

```{python, eval=T}
# shape
df.shape
```

```{python, eval=T}
# column names
list(df) 
```

```{python, eval=T}
# data types by column
df.dtypes  
```


## Missing Values

### R


```{r, eval=T}
# count missing values by columns
colSums(is.na(df)) 

# fill all missing values by 0
df[is.na(df)] <- 0

# fill missing by columns
df %>% replace_na(list(dimension1 = "Unknown", measure1 = 0))
```


### Python

```{python, eval=F}
# count missing by columns
df.isnull().sum()


# fill all missing by 0
df.fillna(0)

# fill missing by columns
df.fillna(value = {"dimension1": "Unknown", "measure1": 0})

```


## Unique row

### R

```{r, eval=T}

# unique row
df %>% distinct()

# unique row by columns
df %>% distinct(dimension1, dimension2, .keep_all = T)

```

### Python

```{python, eval=F}
# unique row
df.drop_duplicates()

# unique row by columns
df.drop_duplicates(subset=('dimension1', 'dimension2'))
```

## Level Count

### R

```{r, eval=T}

# distribution
table(df$dimension1)

# contingency table
table(df$dimension1, df$dimension2)

```

### Python

```{python, eval=F}

# distribution
df.dimension1.value_counts()

# contingency table
pd.crosstab(df.dimension1, df.dimension2)

```


## Summary

### R

```{r, eval=T}

# summarize the total, percent, ratio, and ratio

df %>% 
  group_by(dimension1) %>% 
  summarise(
    measure1 = sum(measure1, na.rm = T),
    measure2 = sum(measure2, na.rm = T),
    count = n()
  ) %>% 
  mutate(
    measure1_percent = measure1/sum(measure1),
    ratio = measure1/measure2
  ) %>% 
  mutate(
    ratio_relativity = ratio/(sum(measure1)/sum(measure2))
  )

```

### Python

```{python, eval=F}

# summarize the total, percent, ratio, and relativity
def oneway(g):
  return(
    pd.Series({
      "measure1": g.measure1.sum(),
      "measure2": g.measure2.sum(),
      "count": len(g),
      "measure1_percent": g.measure1.sum()/df.measure1.sum(),
      "ratio": g.measure1.sum()/g.measure2.sum(),
      "ratio_relativity":
        (g.measure1.sum()/g.measure2.sum())/ 
        (df.measure1.sum()/df.measure2.sum())
    })
  )
  
df.groupby("dimension1").apply(oneway)

```


## Merge

### R

```{r, eval=T}
# join tables with different key names
df2 <- df %>%
  group_by(dimension1, dimension2) %>%
  summarise(
    measure3 = sum(measure1, na.rm = T),
    measure4 = sum(measure2, na.rm = T)
  ) %>%
  rename(dimension3 = dimension1, dimension4 = dimension2)

left_join(df, df2,
  by = c(
    "dimension1" = "dimension3",
    "dimension2" = "dimension4"
  )
)
```

### Python

```{python, eval=F}
# join tables with different key names
# pd.merge(df, df2,
#   how="left", 
#   left_on=["dimesnion1", "dimesnion2"],
#   right_on=["dimesnion3", "dimesnion4"]
# )

```

## Reshape

### R

```{r, eval=T}

# wide to long
df_reshape <- df %>% gather(c("measure1", "measure2"), 
                            key = "measure", value = "values")

# long to wide: the value must be unqiue by other variales
df_reshape %>%
  group_by(dimension1, dimension2, measure) %>%
  summarise(values = sum(values, na.rm = T)) %>% 
  spread(key = measure, value = values)

```

### Python

```{python, eval=F}

df_reshape = pd.melt(df,
  id_vars=['dimension1', 'dimension2'],
  value_vars=['measure1', 'measure2'])

(df_reshape.groupby(['dimension1', 'dimension2', 'variable'],
                    as_index=False)
           .value.sum()
           .pivot_table(index=['dimension1', 'dimension2'],
                        columns='variable', values='value'))

```